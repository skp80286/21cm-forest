{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import F21DataLoader as dl\n",
    "import f21_predict_base as base\n",
    "import Scaling\n",
    "import PS1D\n",
    "import F21Stats as f21stats\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logger = logging.Logger('M')\n",
    "\n",
    "def load_dataset(datafiles, psbatchsize, max_workers=8):\n",
    "    # Lists to store combined data\n",
    "    all_params = []\n",
    "    # Create processor with desired number of worker threads\n",
    "    processor = dl.F21DataLoader(max_workers=max_workers, psbatchsize=psbatchsize, use_bispectrum=True, skip_stats=True, ps_log_bins=True, ps_bins=16, perc_bins_to_use=100, scale_ps=True)\n",
    "\n",
    "    # Process all files and get results\n",
    "    results = processor.process_all_files(datafiles)\n",
    "    logger.info(f\"Finished data loading.\")\n",
    "    # Access results\n",
    "    keys = results['key']\n",
    "    ps = results['ps']\n",
    "    ks = results['ks']\n",
    "    bispec = results['bispectrum']\n",
    "    k_bispec = results['k_bispec']\n",
    "    params = results['params']\n",
    "    freq_axis = results['freq_axis']\n",
    "    logger.info(f\"sample ps:{ps[0]}\")\n",
    "    logger.info(f\"sample ks:{ks[0]}\")\n",
    "    logger.info(f\"sample bispec:{bispec[0]}\")\n",
    "    logger.info(f\"sample k_bispec:{k_bispec[0]}\")\n",
    "    logger.info(f\"sample params:{params[0]}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    logger.info(f\"\\nCombined ps shape: {ps.shape}\")\n",
    "    logger.info(f\"\\nCombined ks shape: {ks.shape}\")\n",
    "    logger.info(f\"\\nCombined bispec shape: {bispec.shape}\")\n",
    "    logger.info(f\"\\nCombined k_bispec shape: {k_bispec.shape}\")\n",
    "    logger.info(f\"Combined parameters shape: {params.shape}\")\n",
    "            \n",
    "    return (ks, ps, k_bispec, bispec, params, keys, freq_axis)\n",
    "\n",
    "def dump_ps(datafile, dir, psbatchsize, save_ks):\n",
    "    file_name = os.path.basename(datafile)  # Extract the filename from the path\n",
    "    file_name_no_ext = os.path.splitext(file_name)[0]  # Remove the extension\n",
    "\n",
    "    ks, ps, k_bispec, bispec, params, keys, freq_axis = load_dataset([datafile], max_workers=1, psbatchsize=1)\n",
    "\n",
    "    if psbatchsize > 1:\n",
    "        \n",
    "        # need to aggregate. use the specified aggregation\n",
    "        n_batches = len(ps) // psbatchsize\n",
    "        ps_batched = np.zeros((n_batches, ps.shape[1]))\n",
    "        bispec_batched = np.zeros((n_batches, bispec.shape[1]))\n",
    "        for i in range(n_batches):\n",
    "            if args.aggtype.lower() == 'mean':\n",
    "                ps_batched[i,:] = np.nanmean(ps[i*psbatchsize:(i+1)*psbatchsize], axis=0)\n",
    "                bispec_batched[i,:] = np.nanmean(bispec[i*psbatchsize:(i+1)*psbatchsize], axis=0)\n",
    "            elif args.aggtype.lower() == 'median':\n",
    "                ps_batched[i,:] = np.nanmedian(ps[i*psbatchsize:(i+1)*psbatchsize], axis=0)\n",
    "                bispec_batched[i,:] = np.nanmedian(bispec[i*psbatchsize:(i+1)*psbatchsize], axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid aggregation type: {args.aggtype}. Use 'mean' or 'median'\")\n",
    "    ps = ps_batched\n",
    "    bispec = bispec_batched\n",
    "    if save_ks:\n",
    "        logger.info(f'Saving PS, bispec data. PS shape:{ps.shape}, ks shape:{ks.shape}, bispec shape: {bispec.shape}, k_bispec shape: {k_bispec.shape}')\n",
    "        np.savetxt(f'{dir}/ks_bin.csv', np.hstack((ks, k_bispec))[0])\n",
    "        logger.info(f\" Saved 'k' bin values to f'{dir}/ks_bin.csv'\")\n",
    "    # Save the PS output to a file\n",
    "    ps_file = f'{dir}/{file_name_no_ext}.csv' \n",
    "    np.savetxt(ps_file, np.hstack((ps, bispec)))\n",
    "    logger.info(f\" Saved PS, bispec to {ps_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, runmode='', telescope='uGMRT', t_int=500):\n",
    "        self.runmode = runmode\n",
    "        self.telescope = telescope\n",
    "        self.t_int = t_int\n",
    "        self.scale_y = True\n",
    "        self.aggtype = 'median'\n",
    "\n",
    "args = Args() \n",
    "\n",
    "dump_ps('../data/21cmFAST_los/F21_noisy/F21_signalonly_21cmFAST_200Mpc_z6.0_fX-2.00_xHI0.44_8kHz.dat', './tmp_out', 1000, False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
